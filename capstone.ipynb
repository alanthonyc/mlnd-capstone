{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Udacity Machine Learning Nanodegree\n",
    "\n",
    "## Capstone Project — Tweet Classifier\n",
    "\n",
    "> *Classify tweets as either __Republican__ or __Democrat__.*\n",
    "\n",
    "The goal of this project is to create a neural network text classifier that performs better then a benchmark Naive Bayes classifier.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 — Examine the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by party:\n",
      "            Handle  Tweet\n",
      "Party                    \n",
      "Democrat     42068  42068\n",
      "Republican   44392  44392\n",
      "\n",
      "Counts by handle:\n",
      "                 Party  Tweet\n",
      "Handle                       \n",
      "AGBecerra          200    200\n",
      "AlanGrayson        200    200\n",
      "AnthonyBrownMD4    200    200\n",
      "AustinScottGA08    200    200\n",
      "BennieGThompson    200    200\n",
      "BettyMcCollum04    200    200\n",
      "BillPascrell       200    200\n",
      "BobbyScott         200    200\n",
      "BradSherman        200    200\n",
      "Call_Me_Dutch      200    200\n",
      "Clyburn            200    200\n",
      "ConawayTX11        200    200\n",
      "CongCulberson      200    200\n",
      "CongMikeSimpson    199    199\n",
      "CongressmanDan     200    200\n",
      "CongressmanGT      200    200\n",
      "CongressmanHice    200    200\n",
      "CongressmanRaja    200    200\n",
      "CongressmanRuiz    200    200\n",
      "DWStweets          200    200\n",
      "DanaRohrabacher    199    199\n",
      "DarrellIssa        200    200\n",
      "DonaldNorcross     200    200\n",
      "DorisMatsui        200    200\n",
      "DrNealDunnFL2      200    200\n",
      "DrPhilRoe          200    200\n",
      "EdWorkforce        200    200\n",
      "EleanorNorton      200    200\n",
      "FinancialCmte      200    200\n",
      "FrankPallone       200    200\n",
      "...                ...    ...\n",
      "gracenapolitano    200    200\n",
      "housebudgetGOP     200    200\n",
      "jahimes            199    199\n",
      "janschakowsky      200    200\n",
      "keithellison       200    200\n",
      "louiseslaughter    200    200\n",
      "michaelcburgess    200    200\n",
      "mikecapuano        200    200\n",
      "nikiinthehouse     200    200\n",
      "pedropierluisi     200    200\n",
      "rep_stevewomack    200    200\n",
      "repbenraylujan     200    200\n",
      "repblumenauer      200    200\n",
      "repcleaver         200    200\n",
      "repdavetrott       200    200\n",
      "repdavidscott      200    200\n",
      "repdinatitus       200    200\n",
      "repdonnaedwards    200    200\n",
      "repdonyoung        200    200\n",
      "repgregwalden      200    200\n",
      "repjimcooper       200    200\n",
      "repjoecrowley      200    200\n",
      "repjohnlewis       200    200\n",
      "replouiegohmert    200    200\n",
      "repmarkpocan       200    200\n",
      "reppittenger       200    200\n",
      "repsandylevin      200    200\n",
      "rosadelauro        200    200\n",
      "sethmoulton        200    200\n",
      "virginiafoxx       200    200\n",
      "\n",
      "[433 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tweets = pd.read_csv('./dataset/ExtractedTweets.csv')\n",
    "\n",
    "tweets.head()\n",
    "\n",
    "\n",
    "\n",
    "party_count = tweets.groupby(['Party',]).count()\n",
    "print (\"Counts by party:\")\n",
    "print(party_count)\n",
    "\n",
    "handles = None\n",
    "handle_counts = None\n",
    "print (\"\\nCounts by handle:\")\n",
    "handles = tweets.groupby('Handle')\n",
    "#for h in handles:\n",
    "#    print h\n",
    "handle_counts = handles.count()\n",
    "print(handle_counts)\n",
    "#handle_counts.mean()\n",
    "#handle_counts.median()\n",
    "#andle_counts = None\n",
    "#andle_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
