{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Udacity Machine Learning Nanodegree\n",
    "\n",
    "## Capstone Project — Tweet Classifier\n",
    "\n",
    "> *Classify tweets as either __Republican__ or __Democrat__.*\n",
    "\n",
    "The goal of this project is to create a neural network text classifier that performs better then a benchmark Naive Bayes classifier.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 — Examine the Dataset\n",
    "\n",
    "Some summary stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 86460\n",
      "------\n",
      "Tweets by party:\n",
      "Party\n",
      "Democrat      42068\n",
      "Republican    44392\n",
      "Name: Tweet, dtype: int64\n",
      "------\n",
      "Mean number tweets per account: 199.676674\n",
      "Median number of tweets per account: 200.000000\n",
      "Number of accounts without exactly two hundred tweets: 17.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tweets = pd.read_csv('./dataset/ExtractedTweets.csv')\n",
    "#tweets.head()\n",
    "print \"Total number of tweets: %i\" % tweets['Tweet'].count()\n",
    "\n",
    "print \"------\"\n",
    "party_count = tweets.groupby(['Party',]).count()\n",
    "print (\"Tweets by party:\")\n",
    "print(party_count['Tweet'])\n",
    "\n",
    "print \"------\"\n",
    "handles = None\n",
    "handle_counts = None\n",
    "handles = tweets.groupby('Handle')\n",
    "handle_counts = handles.count()\n",
    "non_two_hundred = handle_counts[handle_counts['Tweet']!=200]['Tweet'].count()\n",
    "print \"Mean number tweets per account: %f\" % handle_counts['Tweet'].mean()\n",
    "print \"Median number of tweets per account: %f\" % handle_counts['Tweet'].median()\n",
    "print \"Number of accounts without exactly two hundred tweets: %f\" % non_two_hundred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an almost perfectly balanced binary-labeled dataset. There are a total of **86460** tweets.  **42068** (48.65%) are labeled *Democrat*, while **44392** (51.34%) are labeled *Republican*. All but seventeen (17) of the accounts included in this data set made exactly two-hundred (200) tweets each.\n",
    "\n",
    "This data set is ideal for doing a binary classification based solely on the content of the text in the dataset, with minimal influence from data composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 — Vectorize\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts = None\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    RT @NBCLatino: .@RepDarrenSoto noted that Hurr...\n",
      "3    RT @NALCABPolicy: Meeting with @RepDarrenSoto ...\n",
      "Name: Tweet, dtype: object\n",
      "{u'ed': 8, u'nbclatino': 22, u'guzman': 10, u'thanks': 27, u'in': 13, u'repdarrensoto': 24, u'allocated': 3, u'rt': 25, u'for': 9, u'latinoleader': 14, u'marucci': 17, u'hurricane': 12, u'approximately': 4, u'to': 31, u'damages': 7, u'nalcabpolicy': 20, u'has': 11, u'meeting': 19, u'congress': 6, u'that': 28, u'90': 1, u'with': 32, u'maria': 16, u'billion': 5, u'about': 2, u'nalcabpolicy2018': 21, u'18': 0, u'taking': 26, u'time': 30, u'meet': 18, u'the': 29, u'noted': 23, u'left': 15}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 126329)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train_counts = vectorizer.transform(tweets['Tweet'])\n",
    "#X_train_counts.shape\n",
    "\n",
    "tweet_sample = tweets['Tweet'][2:4]\n",
    "print tweet_sample\n",
    "\n",
    "v = CountVectorizer()\n",
    "v.fit(tweet_sample)\n",
    "\n",
    "print(v.vocabulary_)\n",
    "\n",
    "t = vectorizer.transform(tweets['Tweet'][2:3])\n",
    "t.shape\n",
    "#help(t)\n",
    "#for i in range(1,len(t[1][0].toarray())):\n",
    "#    print i\n",
    "\n",
    "#vectorizer.vocabulary_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "---\n",
      "  (0, 55875)\t1\n",
      "  (0, 105638)\t1\n",
      "  (0, 53345)\t1\n",
      "  (0, 28191)\t1\n",
      "  (0, 44016)\t1\n",
      "  (0, 80981)\t1\n",
      "  (0, 106022)\t1\n",
      "  (0, 56314)\t1\n",
      "  (0, 73387)\t1\n",
      "  (0, 83482)\t1\n",
      "  (0, 114098)\t1\n",
      "  (0, 116734)\t1\n",
      "  (0, 29192)\t1\n",
      "  (0, 34908)\t1\n",
      "---\n",
      "RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia…\n",
      "R\n",
      "T\n",
      " \n",
      "@\n",
      "W\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "H\n",
      "a\n",
      "v\n",
      "e\n",
      "n\n",
      "S\n",
      "u\n",
      "n\n",
      ":\n",
      " \n",
      "W\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "H\n",
      "a\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "/\n",
      " \n",
      "A\n",
      "l\n",
      "t\n",
      "a\n",
      " \n",
      "V\n",
      "i\n",
      "s\n",
      "t\n",
      "a\n",
      " \n",
      "t\n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      " \n",
      "r\n",
      "e\n",
      "c\n",
      "o\n",
      "g\n",
      "n\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "@\n",
      "R\n",
      "e\n",
      "p\n",
      "D\n",
      "a\n",
      "r\n",
      "r\n",
      "e\n",
      "n\n",
      "S\n",
      "o\n",
      "t\n",
      "o\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "N\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "T\n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "A\n",
      "p\n",
      "p\n",
      "r\n",
      "e\n",
      "c\n",
      "i\n",
      "a\n",
      "�\n",
      "�\n",
      "�\n"
     ]
    }
   ],
   "source": [
    "print count_vect.vocabulary_.get(u'Haven')\n",
    "\n",
    "count_vect\n",
    "\n",
    "print \"---\"\n",
    "print X_train_counts[50596]\n",
    "print \"---\"\n",
    "#print X_train_counts[1]\n",
    "\n",
    "print tweets['Tweet'][1]\n",
    "for i in range(0,len(tweets['Tweet'][1])):\n",
    "    print tweets['Tweet'][1][i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
