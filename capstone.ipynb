{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Udacity Machine Learning Nanodegree\n",
    "\n",
    "## Capstone Project — Tweet Classifier\n",
    "\n",
    "> *Classify tweets as either __Republican__ or __Democrat__.*\n",
    "\n",
    "The goal of this project is to create a neural network text classifier that performs better then a benchmark Naive Bayes classifier.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 1 — Examine the Dataset\n",
    "\n",
    "Some summary stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 86460\n",
      "------\n",
      "Tweets by party:\n",
      "Party\n",
      "Democrat      42068\n",
      "Republican    44392\n",
      "Name: Tweet, dtype: int64\n",
      "------\n",
      "Mean number tweets per account: 199.676674\n",
      "Median number of tweets per account: 200.000000\n",
      "Number of accounts without exactly two hundred tweets: 17.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tweets = pd.read_csv('./dataset/ExtractedTweets.csv')\n",
    "\n",
    "tweet_texts = tweets['Tweet']\n",
    "tweet_texts = tweets.Tweet\n",
    "\n",
    "print \"Total number of tweets: %i\" % tweets['Tweet'].count()\n",
    "\n",
    "print \"------\"\n",
    "party_count = tweets.groupby(['Party',]).count()\n",
    "print (\"Tweets by party:\")\n",
    "print(party_count['Tweet'])\n",
    "\n",
    "print \"------\"\n",
    "handles = None\n",
    "handle_counts = None\n",
    "handles = tweets.groupby('Handle')\n",
    "handle_counts = handles.count()\n",
    "non_two_hundred = handle_counts[handle_counts['Tweet']!=200]['Tweet'].count()\n",
    "print \"Mean number tweets per account: %f\" % handle_counts['Tweet'].mean()\n",
    "print \"Median number of tweets per account: %f\" % handle_counts['Tweet'].median()\n",
    "print \"Number of accounts without exactly two hundred tweets: %f\" % non_two_hundred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is an almost perfectly balanced binary-labeled dataset. There are a total of **86460** tweets.  **42068** (48.65%) are labeled *Democrat*, while **44392** (51.34%) are labeled *Republican*. All but seventeen (17) of the accounts included in this data set made exactly two-hundred (200) tweets each.\n",
    "\n",
    "This data set is ideal for doing a binary classification based solely on the content of the text in the dataset, with minimal influence from data composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 2 — Vectorize: Bag-of-Words / tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86460, 126329)\n"
     ]
    }
   ],
   "source": [
    "X_train_counts = None\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(tweet_texts)\n",
    "\n",
    "print X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Today, Senate Dems vote to #SaveTheInternet. P...\n",
      "1    RT @WinterHavenSun: Winter Haven resident / Al...\n",
      "2    RT @NBCLatino: .@RepDarrenSoto noted that Hurr...\n",
      "3    RT @NALCABPolicy: Meeting with @RepDarrenSoto ...\n",
      "4    RT @Vegalteno: Hurricane season starts on June...\n",
      "5    RT @EmgageActionFL: Thank you to all who came ...\n",
      "6    Hurricane Maria left approx $90 billion in dam...\n",
      "7    RT @Tharryry: I am delighted that @RepDarrenSo...\n",
      "8    RT @HispanicCaucus: Trump's anti-immigrant pol...\n",
      "9    RT @RepStephMurphy: Great joining @WeAreUnidos...\n",
      "Name: Tweet, dtype: object\n",
      "RangeIndex(start=0, stop=10, step=1)\n"
     ]
    }
   ],
   "source": [
    "tweet_sample = tweet_texts[0:10]\n",
    "print tweet_sample\n",
    "print tweet_sample.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126329\n",
      "index of 'senate': 98443\n",
      "[ 7.15796257  5.59322484 11.67430154 ... 11.67430154 11.67430154\n",
      " 11.26883644]\n",
      "tfidf of 'senate': 5.598956\n",
      "\n",
      "__________\n",
      "Sample tweet: 'Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House… https://t.co/n3tggDLU1L'\n",
      "Tweet breakdown:\n",
      "  (0, 74945)\t0.4856049705506262\n",
      "  (0, 28191)\t0.052833650863872844\n",
      "  (0, 53345)\t0.05292198936794678\n",
      "  (0, 52688)\t0.17166959365086887\n",
      "  (0, 105638)\t0.06484465864207267\n",
      "  (0, 55875)\t0.09591415175080434\n",
      "  (0, 51255)\t0.1902203520427344\n",
      "  (0, 66211)\t0.22046448919469594\n",
      "  (0, 76460)\t0.2783065606436417\n",
      "  (0, 99761)\t0.3525527653079148\n",
      "  (0, 103134)\t0.1957869759852857\n",
      "  (0, 87421)\t0.19415404163917044\n",
      "  (0, 97338)\t0.3492886551285527\n",
      "  (0, 106897)\t0.13840569968604383\n",
      "  (0, 114602)\t0.21903540977450434\n",
      "  (0, 33246)\t0.3015487758119325\n",
      "  (0, 98443)\t0.23289450050801297\n",
      "  (0, 106944)\t0.13729330830673972\n",
      "__________\n",
      "\n",
      "106944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(86460, 126329)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tfv = TfidfVectorizer()\n",
    "doc = tfv.fit_transform(tweets['Tweet'])\n",
    "print(len(tfv.vocabulary_.keys()))\n",
    "index_of_senate = tfv.vocabulary_.get(u'senate')\n",
    "print \"index of 'senate': %i\" % index_of_senate\n",
    "print tfv.idf_\n",
    "print \"tfidf of 'senate': %f\" % tfv.idf_[index_of_senate]\n",
    "\n",
    "print \"\\n__________\"\n",
    "print \"Sample tweet: '%s'\" % tweets['Tweet'][0]\n",
    "print \"Tweet breakdown:\"\n",
    "print doc[0]\n",
    "print \"__________\\n\"\n",
    "\n",
    "print tfv.vocabulary_.get(u'today')\n",
    "\n",
    "\n",
    "tfxfr = TfidfTransformer()\n",
    "X_train_tfidf = tfxfr.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Democrat' 'Republican' 'Republican' 'Republican' 'Democrat']\n"
     ]
    }
   ],
   "source": [
    "#party_names = tweets['Party']\n",
    "party_names = tweets.Party\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, party_names)\n",
    "\n",
    "test1 = ['I love savetheinternet. netneutrality', \\\n",
    "         'Christian values are very important. SAD!', \\\n",
    "         'cannot believe the audacity of the liberal party',\\\n",
    "         'with god’s help, we can end abortion',\n",
    "         'we must save obamacare from destruction #netneutrality']\n",
    "test1_counts = tfv.transform(test1)\n",
    "test1_tfidf = tfxfr.transform(test1_counts)\n",
    "p = clf.predict(test1_tfidf)\n",
    "print p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3 — Baseline Classifier: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "tweet_accounts = tweets.iloc[:, :2].drop_duplicates()\n",
    "accounts_train, accounts_test = train_test_split(tweet_accounts.Handle, stratify=tweet_accounts.Party, \\\n",
    "                                                 test_size=0.2, random_state=43)\n",
    "\n",
    "tweets_train = tweets[tweets.Handle.isin(accounts_train)].reset_index().drop('index', axis=1)\n",
    "tweets_test = tweets[tweets.Handle.isin(accounts_test)].reset_index().drop('index', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7505605058924979"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mnb_pipeline = Pipeline([('vec', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "mnb_pipeline.fit(tweets_train.Tweet, tweets_train.Party)\n",
    "\n",
    "p = mnb_pipeline.predict(tweets_test.Tweet)\n",
    "np.mean(p == tweets_test.Party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
